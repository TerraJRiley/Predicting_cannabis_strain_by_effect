{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Natural Language Processing libraries, initiations and functions\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-zA-Z]',' ', text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    return \" \".join([lemmer.lemmatize(word) for word \n",
    "                     in tokens if len(word) > 1 and not word in stop_words])\n",
    "\n",
    "\n",
    "\n",
    "# Cvec, Standard\n",
    "cvec = CountVectorizer(analyzer = \"word\",\n",
    "                       min_df = 2,\n",
    "                       preprocessor = preprocess,\n",
    "                       stop_words = 'english') \n",
    "# Cvec DF\n",
    "#df_words = pd.DataFrame(cvec.fit_transform(df['doc_column']).todense(), \n",
    "#                        columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Effects</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-Og</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Creative,Energetic,Tingly,Euphoric,Relaxed</td>\n",
       "      <td>Earthy,Sweet,Citrus</td>\n",
       "      <td>$100 OG is a 50/50 hybrid strain that packs a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98-White-Widow</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Relaxed,Aroused,Creative,Happy,Energetic</td>\n",
       "      <td>Flowery,Violet,Diesel</td>\n",
       "      <td>The ‘98 Aloha White Widow is an especially pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024</td>\n",
       "      <td>sativa</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Uplifted,Happy,Relaxed,Energetic,Creative</td>\n",
       "      <td>Spicy/Herbal,Sage,Woody</td>\n",
       "      <td>1024 is a sativa-dominant hybrid bred in Spain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13-Dawgs</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Tingly,Creative,Hungry,Relaxed,Uplifted</td>\n",
       "      <td>Apricot,Citrus,Grapefruit</td>\n",
       "      <td>13 Dawgs is a hybrid of G13 and Chemdawg genet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K-Gold</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Happy,Relaxed,Euphoric,Uplifted,Talkative</td>\n",
       "      <td>Citrus,Earthy,Orange</td>\n",
       "      <td>Also known as Kosher Tangie, 24k Gold is a 60%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Strain    Type  Rating                                     Effects  \\\n",
       "0          100-Og  hybrid     4.0  Creative,Energetic,Tingly,Euphoric,Relaxed   \n",
       "1  98-White-Widow  hybrid     4.7    Relaxed,Aroused,Creative,Happy,Energetic   \n",
       "2            1024  sativa     4.4   Uplifted,Happy,Relaxed,Energetic,Creative   \n",
       "3        13-Dawgs  hybrid     4.2     Tingly,Creative,Hungry,Relaxed,Uplifted   \n",
       "4        24K-Gold  hybrid     4.6   Happy,Relaxed,Euphoric,Uplifted,Talkative   \n",
       "\n",
       "                      Flavor  \\\n",
       "0        Earthy,Sweet,Citrus   \n",
       "1      Flowery,Violet,Diesel   \n",
       "2    Spicy/Herbal,Sage,Woody   \n",
       "3  Apricot,Citrus,Grapefruit   \n",
       "4       Citrus,Earthy,Orange   \n",
       "\n",
       "                                         Description  \n",
       "0  $100 OG is a 50/50 hybrid strain that packs a ...  \n",
       "1  The ‘98 Aloha White Widow is an especially pot...  \n",
       "2  1024 is a sativa-dominant hybrid bred in Spain...  \n",
       "3  13 Dawgs is a hybrid of G13 and Chemdawg genet...  \n",
       "4  Also known as Kosher Tangie, 24k Gold is a 60%...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_canna = pd.read_csv('./../../cannabis.csv')\n",
    "df_canna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_canna['Starting_dex'] = df_canna.index\n",
    "df_canna.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_canna['Type'] != 'hybrid'\n",
    "df_canna = df_canna[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_canna.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_canna['Type'] = df_canna['Type'].map( lambda x: {'indica': 1,\n",
    " 'sativa': 0}[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['le'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "df_effects = pd.DataFrame(cvec.fit_transform(df_canna['Effects']).todense(), \n",
    "                        columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flavors = pd.DataFrame(cvec.fit_transform(df_canna['Flavor']).todense(), \n",
    "                        columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_E = {}\n",
    "for col in df_effects.columns:\n",
    "    dict_E[col] = ('E_' + col)\n",
    "\n",
    "df_effects.rename(columns=dict_E, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_F = {}\n",
    "for col in df_flavors.columns:\n",
    "    dict_F[col] = ('F_' + col)\n",
    "\n",
    "df_flavors.rename(columns=dict_F, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_canna.loc[:,[\"Type\", \"Rating\"]], df_effects\n",
    "                #, df_flavors\n",
    "               ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Type']\n",
    "X = df.drop(['Type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#import sklearn.metrics as metrics\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.851985559566787\n",
      "Test:  0.8700361010830325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.847459654776728"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Train:', model.score(X_train,y_train))\n",
    "print('Test: ',  model.score(X_test,y_test))\n",
    "np.average(cross_val_score(model, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9530685920577617\n",
      "Test:  0.7978339350180506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8230913840669937"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Train:', model.score(X_train,y_train))\n",
    "print('Test: ',  model.score(X_test,y_test))\n",
    "np.average(cross_val_score(model, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.8724428399518652\n",
      "Test:  0.8267148014440433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8267047535340217"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Train:', model.score(X_train,y_train))\n",
    "print('Test: ',  model.score(X_test,y_test))\n",
    "np.average(cross_val_score(model, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    187\n",
       "0     90\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_hat).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    680\n",
       "0    428\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_canna['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we turn this into a %-age problem?\n",
    "Can we cut down and isolate the values that're the most important to determining the best quality?\n",
    "I'm in a weird argument with myself in which, TECHNICALLY I made a better model and thus satisfied today's requirements.  BUT I HAVE SUCH MANY OTHER BETTER IDEAS.  BUT ALSO HOLY BUTTS I NEED TO TAKE THE REST OF TODAY (AND MAYBE TOMORROW) EASY."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
